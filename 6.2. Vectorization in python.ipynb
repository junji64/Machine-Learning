{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "## What is Vectorization?\n\n$ z = w^T x + b $ where \n$ \\mathbf{w}  = \\left[\n\\begin{matrix}\nw_1\\\\ w_2\\\\ \\vdots\\\\ w_{n_x}\n\\end{matrix}\n\\right] $ and \n$ \\mathbf{x}  = \\left[\n\\begin{matrix}\nx_1\\\\ x_2\\\\ \\vdots\\\\ x_{n_x}\n\\end{matrix}\n\\right] $\n\n#### Non-vectorized implementation\n\n>z = 0\n>\n>for i in range(n_x):\n>\n>     z += w[i] * x[i]\n>\n>z += b\n\n#### Vetorized implementation\n\n>z = np.dot(w,x)\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport time\n\na = np.random.rand(1000000)\nb = np.random.rand(1000000)\n\ntic = time.time()\nc = np.dot(a,b)\ntoc = time.time()\n\nprint(c)\nprint(\"Vectorized version:\" + str(1000*(toc-tic)) + \"ms\")\n\nc = 0\ntic = time.time()\nfor i in range(1000000):\n    c += a[i]*b[i]\ntoc = time.time()\n\nprint(c)\nprint(\"For loop:\" + str(1000*(toc-tic)) + \"ms\")",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "250062.17600667116\nVectorized version:1.2202262878417969ms\n250062.17600667023\nFor loop:537.5235080718994ms\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Neural network programming guideline\n\n가능하면 명시적인 for 루프를 피하십시오..\n\n### matrix vector multiplication $u = Av$\n\n$ u_i = \\sum_j A_{ij} v_j$\n\n#### Non-vectorized implementation\n\n\n>\n> u = np.zeros((n,1))\n>\n> for i in range(m):\n>\n>     for j in range(n):\n>\n>          u[i] += A[i][j] * v[j]\n\n\n#### Vetorized implementation\n\n> u = np.dot(A,v)\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### application of a function on a matrix/vector\n\n$ \\mathbf{v}  = \\left[\n\\begin{matrix}\nv_1\\\\ v_2\\\\ \\vdots\\\\ v_{n}\n\\end{matrix}\n\\right] $ \n$\\rightarrow$ \n$ \\mathbf{u}  = \\left[\n\\begin{matrix}\ne^{v_1}\\\\ e^{v_2}\\\\ \\vdots\\\\ e^{v_n}\n\\end{matrix}\n\\right] $ \n\n#### Non-vectorized implementation\n\n>\n> u = np.zeros((n,1))\n>\n> for i in range(n):\n>\n>      u[i] += math.exp(v[i])\n>\n\n#### Vetorized implementation\n\n> u = np.exp(v)\n\nSimilarly,\n> np.log(v)\n\n> np.abs(v)\n\n> np.maximum(v,0)\n\n> v**2\n\n> 1/v"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": " ## Logistic regression derivatives\n \n$z^{(1)} = w^Tx^{(1)} + b$ $\\Rightarrow$  $a^{(1)} = \\sigma(z^{(1)})$\n\n$z^{(2)} = w^Tx^{(2)} + b$ $\\Rightarrow$  $a^{(2)} = \\sigma(z^{(2)})$\n\n$z^{(3)} = w^Tx^{(3)} + b$ $\\Rightarrow$  $a^{(3)} = \\sigma(z^{(3)})$\n\n$\\cdots$\n\nwhere $X$ is $(n_x,m)$ matrix, $\\in \\mathbb{R}^{n_x \\times m}$.\n\n$ \\mathbf{X}  =  \\left[ \\begin{matrix} | & | & \\cdots & | \\\\\nx^{(1)} & x^{(2)} & \\cdots & x^{(m)} \\\\\n | & | & \\cdots & | \\end{matrix} \\right] $ \n\nthen\n\n$  \\left[ z^{(1)},  z^{(2)},  \\cdots  z^{(m)}  \\right] = w^T  \\mathbf{X} + [b, b, \\cdots b] \\\\\n=  [w^Tx^{(1)}+b, w^Tx^{(2)}+b,\\cdots,w^Tx^{(m)}+b] $ \n\nthen in python\n\n> z = np.dot(w.T, X) + b\n\nwhere $b$ can be a real number in size$(1,1)$ due to the \"broadcasting\", and\n\n$ A = \\left[ a^{(1)},  a^{(2)},  \\cdots  a^{(m)}  \\right] = \\sigma(z) $ \n\n> A = sigma(z)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Vectorizing Logistic Regression\n\n#### Without vectorization\n\n$dz^{(1)} = a^{(1)} - y^{(1)}$,  $dz^{(2)} = a^{(2)} - y^{(2)}$, $ \\cdots$\n\n$dZ = [dz^{(1)} dz^{(2)} \\cdots dz^{(m)} ] $\n\n$ A = \\left[ a^{(1)},  a^{(2)},  \\cdots  a^{(m)}  \\right]$\n\n$ Y = \\left[ y^{(1)},  y^{(2)},  \\cdots  y^{(m)}  \\right]$\n\n$ dZ = A - Y =  \\left[ a^{(1)}-y^{(1)},  a^{(2)}-y^{(2)},  \\cdots  a^{(m)}-y^{(m)}  \\right] $\n\n\n$ dw = 0 $  \n$ dw += x^{(1)}dz^{(1)} $    \n$ dw += x^{(2)}dz^{(2)} $    \n$ \\cdots $   \n$ dw  += x^{(m)}dz^{(m)}$   \n$ dw /=m $\n\n$ db = 0 $   \n$ db  += dz^{(1)} $   \n$ db  += dz^{(2)} $   \n$ \\cdots $   \n$ db  += dz^{(m)} $   \n$ db /=m $\n\n#### With vectorization\n\n```\ndb = 1 / m * np.sum(dz)\ndw = 1 / m * np.dot(X,dz.T)\n```"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**without vectorization**:\n```\nJ = 0, dw1=0, dw2=0, db=0\n\nfor iter in range(1000):\n    for i in range(m):\n        Z[i] = w.T X[i] + b\n        a[i] = sigma(z[i])\n        J += -[y[i]*np.log(a[i]) + (1-y[i])*np.log(1-a[i])]\n        dz[i] = a[i] - y[i]\n        dw1 += x[i][1] * dz[i]\n        dw2 += x[i][2] * dz[i]\n        db += dz[i]\n    J = J / m, dw1 = dw/m, dw2 = dw2/m, db = db/m\n```\n\n**With vectoriazation**:\n```\nfor iter in range(1000):\n    Z = np.dot(w.T, X) + b\n    A = sigmoid(Z)\n    dZ = A - Y\n    dw = 1/m * np.dot(X,dZ.T)\n    db = 1/m * np.sum(dZ)\n    w = w - alpha*dw\n    b = b - alpha*db\n```"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Broadcasting example\n\nCaliries from Carbs, Proteins, Fats in 100g of different foods:\n\n$ \\begin{matrix}  \\cdots \\cdots & Apples & Beef & Eggs & Potatoes  \\end{matrix}$\n\n$ \\begin{matrix}   Carb \\\\ Protain \\\\ Fat  \\end{matrix}$\n$ \\left[ \\begin{matrix} \n 56.0 & 0.0 & 4.4 & 68.0 \\\\\n 1.2 & 104.0 & 52.0 & 8.0 \\\\\n 1.8 & 135.0 & 99.0 & 0.9 \n \\end{matrix} \\right] \n $\n \n Calculate % of calories from Carb, Protain, Fat. Can you do this without explicit for-loop?\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\n\nA = np.array([[56.0, 0.0, 4.4, 68.0],\n             [1.2, 104.0, 52.0, 8.0],\n             [1.8, 135.0, 99.0, 0.9]])\nprint(A)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[ 56.    0.    4.4  68. ]\n [  1.2 104.   52.    8. ]\n [  1.8 135.   99.    0.9]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cal = A.sum(axis=0)\nprint(cal)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[ 59.  239.  155.4  76.9]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "percentage = 100 * A / cal.reshape(1,4)  # or percentage = 100 * A / cal\nprint(percentage)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[94.91525424  0.          2.83140283 88.42652796]\n [ 2.03389831 43.51464435 33.46203346 10.40312094]\n [ 3.05084746 56.48535565 63.70656371  1.17035111]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "$  \\left[ \\begin{matrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{matrix}  \\right]  + 100 =  \\left[ \\begin{matrix} 101 \\\\ 102 \\\\ 103 \\\\ 104 \\end{matrix}  \\right]$\n\n$  \\left[ \\begin{matrix} 1 & 2 & 3\\\\\n4 & 5 & 6 \\end{matrix}  \\right]  + \\left[ \\begin{matrix} 100 & 200 & 300 \\end{matrix}  \\right]\n= \\left[ \\begin{matrix} 101 & 202 & 303\\\\\n104 & 205 & 306 \\end{matrix}  \\right]  $\n\n$  \\left[ \\begin{matrix} 1 & 2 & 3\\\\\n4 & 5 & 6 \\end{matrix}  \\right]  + \n\\left[ \\begin{matrix} 100 \\\\ 200  \\end{matrix}  \\right]\n= \\left[ \\begin{matrix} 101 & 102 & 103\\\\\n204 & 205 & 206 \\end{matrix}  \\right]  $\n\n\n#### General Principle\n\n$$ \\text{matrix in size of  } (m,n)  \\text{   } \\begin{matrix} + \\\\ - \\\\ * \\\\ /   \\end{matrix} \\text{   } \\begin{matrix}  \\text{matrix in size of  }  (1,n) \\Rightarrow (m,n) \\\\ \\text{matrix in size of  }  (m, 1) \\Rightarrow (m,n) \\end{matrix}$$\n$ \\left[ \\begin{matrix} 1 \\\\ 2 \\\\3  \\end{matrix} \\right] + 100 = \\left[ \\begin{matrix} 101 \\\\ 102 \\\\ 103  \\end{matrix} \\right] $\n\n$ \\left[ \\begin{matrix} 1& 2& 3  \\end{matrix} \\right] + 100 = \\left[ \\begin{matrix} 101 & 102 & 103  \\end{matrix} \\right] $"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Python-numpy vectors\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\n\na = np.random.randn(5)     # => don't use it !\nprint(a)",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[ 0.18624956  0.28232509 -0.90260203  0.2089896  -1.16819876]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(a.shape)    # rank 1 array =",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(5,)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(a.T)        # same as a",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[ 0.18624956  0.28232509 -0.90260203  0.2089896  -1.16819876]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(np.dot(a,a.T))",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "2.3374517776930843\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "a = np.random.randn(5,1)  # a column vector => use this !\nprint(a)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[ 1.08409355]\n [-0.34657684]\n [-0.41501582]\n [ 1.34656157]\n [ 1.58396164]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(a.T)",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[ 1.08409355 -0.34657684 -0.41501582  1.34656157  1.58396164]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(np.dot(a, a.T))",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[ 1.17525883 -0.37572172 -0.44991597  1.45979871  1.7171626 ]\n [-0.37572172  0.1201155   0.14383487 -0.46668705 -0.54896442]\n [-0.44991597  0.14383487  0.17223813 -0.55884435 -0.65736914]\n [ 1.45979871 -0.46668705 -0.55884435  1.81322805  2.13290186]\n [ 1.7171626  -0.54896442 -0.65736914  2.13290186  2.50893447]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "assert a.shape == (5,1)",
      "execution_count": 26,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}