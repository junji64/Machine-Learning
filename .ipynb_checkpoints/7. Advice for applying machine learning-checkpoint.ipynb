{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Advice for applying machine learning\n\n## 다음에 무엇을 할 지 결정하기\n\n#### 학습 알고리즘 디버깅:\n\n당신이 집 가격을 예측하기 위해서 정규화된 선형회귀를 구현했다고 가정해보자.\n\n\n$$J(\\theta) =  { 1 \\over 2m} \\left[ \\sum_{i=1}^m (h_\\theta(x^{(i)})- y^{(i)})^2 +   \\lambda \\sum_{j=1}^n \\theta_j^2 \\right]$$\n\n\n그러나, 당신의 가설을 새로운 집들 자료에 시험했을 때, 그 추측에서 받아드릴 수\n없을 정도로 큰 오차를 만드는 것을 발견했다. 당신은 다음에 무엇을 시도해야\n하는가?\n\n* 더 많은 훈련자료를 얻는다.\n\n* 더 적은 특징집합으로 시도해본다.\n\n* 추가적인 특징들로 시도해본다.\n\n* 고차원 항들을 추가해 본다. $(x_1^2, x_2^2, x_1x_2, etc.)$\n\n* $\\lambda$ 를 감소시켜본다.\n\n* $\\lambda$ 를 증가시켜본다.\n\n#### 기계학습 진단:\n\n진단(Diagnostic): 학습알고리즘에서 가지고 무엇이 작동하고\n무엇이 작동하지 않는 지에 대한, 그리고 그 성능을 어떻게\n최대로 개선할 수 있는 지에 대한 안내에 대한 통찰을 얻기\n위해서 얻기 위해서 당신이 실행할 수 있는 시험.\n\n진단은 구현에 시간이 걸릴 수는 있으나, 실행하는 것이\n당신의 시간을 가장 잘 사용하는 것일 수 있다."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 가설(hypothesis)을 평가하기\n\n#### 당신의 가설을 평가하기\n\n<img src=\"./images/reg-graph.png\" width=\"200\" >\n\n$ h_\\theta(x) = \\theta_0 + \\theta_1 x +\\theta_2 x^2 +\\theta_3 x^3 +\\theta_4 x^4 $\n\n훈련자료 집합에 없는 새로운 자료에 일반화하는데 실패\n\n$\\begin{align}\nx_1 = & \\text{ size of house }\\\\\nx_2 = & \\text{ no. of bedrooms } \\\\\nx_3 = & \\text{ no. of floors } \\\\\nx_4 = & \\text{ age of house } \\\\\nx_5 = & \\text{ average income in neighborhood }\\\\\nx_6 = & \\text{ kitchen size } \\\\\n\\vdots & \\vdots \\\\\nx_{100} = & \\\\\n\\end{align}$ \n\n\nEvaluating your hypothesis\n\nDataset:\n\n| Size | Price | \n|------|-------|------- \n| 2104 | 400   |  $(x^{(1)}, y^{(1)})$\n|1600 | 330  |  $(x^{(2)}, y^{(2)})$\n| 2400 | 369 | $\\vdots$\n|1416 | 232| $\\vdots$\n| 3000 | 540| $\\vdots$\n| 1985 | 300| $(x^{(m)}, y^{(m)})$\n|1534 | 315  |   $(x_{test}^{(1)}, y_{test}^{(1)})$\n| 1427 | 199  | $(x_{test}^{(2)}, y_{test}^{(2)})$\n| 1380 | 212   |  $\\vdots$\n| 1494 | 243  |  $(x_{test}^{(m_{test})}, y_{test}^{(m_{test})})$\n\n\n\n\n\n선형회귀에 대한 훈련/시험과정\n\n훈련자료로부터 파라메타 를 학습 (훈련 오차 를\n최소화함으로 )\n\n시험집합(test set) 오차를 계산 :\n\n\n\n로지스틱회귀에 대한 훈련/시험 과정\n\n훈련자료로부터 파라메타 를 학습\n\n시험집합(test set) 오차를 계산 :\n\n$$ J_{test}(\\theta) = {1 \\over m_{test}}  \\sum_{i=1}^{m_test}  y_{test}^{(i)} \\log (h_\\theta(x_{test}^{(i)})) + (1 -y_{test}^{(i)}) \\log h_\\theta(x_{test}^{(i)})$$\n\n\n오분류 오차 (0/1 misclassification error):"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 모델 선택과 훈련/검증/시험 집합들\n\n#### 과적합(Overfitting) 예\n\n<img src=\"./images/reg-graph.png\" width=\"200\" >\n\n$ h_\\theta(x) = \\theta_0 + \\theta_1 x +\\theta_2 x^2 +\\theta_3 x^3 +\\theta_4 x^4 $\n\n매개 변수가 일부 데이터 세트 (트레이닝 세트)에 적합하면 해당 데이터에서 측정 된 매개 변수의 오류 (훈련 오류 xxxxx)가 실제 일반화 오류보다 낮을 수 있습니다.\nsize\n\nprice\n\n파라메타들이\n\n어떤 자료집합 (training set)에\n적합되면, 그 자료에서 측정된\n파라메타들의 오차는 (훈련오차\nxxxx ) 실제 일반화된 오차보다\n낮을 가능성이 있다.\n\n#### 모델 선택\n\n1. $h_\\theta (x) = \\theta_0 + \\theta_1 x$ \n\n2. $h_\\theta (x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2$ \n\n3. $h_\\theta (x) = \\theta_0 + \\theta_1 x + \\cdots + \\theta_3 x^3$ \n\n$\\vdots$\n\n10.  $h_\\theta (x) = \\theta_0 + \\theta_1 x + \\cdots + \\theta_{10} x^{10}$ \n\n선택\n\n모델이 얼마나 잘 일반화하는가? 시험 집합 오차를 보고한다\n.\n\n문제: 는 일반화 오차의 낙관적 추정일 가능성이 있다. 즉,\n우리의 추가 파라메타 ( = degree of polynomial) 가 시험자료에 적합된다.\n\nEvaluating your hypothesis\n\nDataset:\n\n| Size | Price | \n|------|-------|------- \n| 2104 | 400   |  $(x^{(1)}, y^{(1)})$\n|1600 | 330  |  $(x^{(2)}, y^{(2)})$\n| 2400 | 369 | $\\vdots$\n|1416 | 232| $(x^{(m)}, y^{(m)})$\n| 3000 | 540| $(x_{CV}^{(1)}, y_{CV}^{(1)})$\n| 1985 | 300| $\\vdots$\n|1534 | 315  |   $(x_{CV}^{(m_{CV})}, y_{CV}^{(m_{CV})})$\n| 1427 | 199  | $(x_{test}^{(1)}, y_{test}^{(1)})$\n| 1380 | 212   |  $\\vdots$\n| 1494 | 243  |  $(x_{test}^{(m_{test})}, y_{test}^{(m_{test})})$\n\n\n$$J(\\theta) =  { 1 \\over 2m} \\left[ \\sum_{i=1}^m (h_\\theta(x^{(i)})- y^{(i)})^2 +   \\lambda \\sum_{j=1}^n \\theta_j^2 \\right]$$"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}