{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Machine Learning System design \n### 할 일의 우선순위를 매기기: 스팸(Spam) 분류 예\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "\n#### 스팸(spam) 분류기 구축하기\n\n**Spam (1)**\n<pre>\nFrom: cheapsales@buystufffromme.com\nTo: ang@cs.stanford.edu\nSubject: Buy now!\n\nDeal of the week! Buy now!\nRolex w4tchs - $100\nMed1cine (any kind) - $50\nAlso low cost M0rgages\navailable.\n</pre>\n\n***\n\n**Non-spam (0)**\n<pre>\nFrom: Alfred Ng\nTo: ang@cs.stanford.edu\nSubject: Christmas dates?\nHey Andrew,\nWas talking to Mom about plans\nfor Xmas. When do you get off\nwork. Meet Dec 22?\nAlf\n</pre>\n\n***\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### 스팸 분류기 구축\n\n지도(supervised) 학습. $x = $ features of email.\n\n$y = $ spam (1) or not spam (0).\n\n특징 $x$ : 스팸/스팸 아님을 나타내는 100 단어들을 선택한다. \n\ne.g. deal, buy, discount, andrew, now, $\\cdots$\n\n$x = \\begin{bmatrix}\n0  \\\\\n1  \\\\\n1  \\\\\n0  \\\\\n\\vdots \\\\\n1  \\\\\n\\vdots \\\\\n\\end{bmatrix}\n\\leftarrow \\begin{bmatrix}\nandrew  \\\\\nbuy \\\\\ndeal  \\\\\ndiscount  \\\\\n\\vdots \\\\\nnow  \\\\\n\\vdots \\\\\n\\end{bmatrix}, \\quad x \\in \\mathbb{R}^{100}, \\quad x_j = \\begin{cases} 1 \\quad \\text{if word j appears in email} \\\\ 0 \\quad \\text{otherwise} \\end{cases}$\n<pre>\nFrom: cheapsales@buystufffromme.com\nTo: ang@cs.stanford.edu\nSubject: Buy now!\nDeal of the week! Buy now!\n</pre>\n\n주의: 실제로는, 손으로 100 단어들을 선택하기 보다는, 훈련자료에서 가장 자주\n나오는 단어들을 (10,000 ~ 50,000) 선택한다.\n"
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "\n#### 스팸 분류기 구축\n오류를 낮추기 위해 시간을 어떻게 사용해야 하는가?\n- 많은 자료를 수집\n  - E.g. “honeypot” 프로젝트.\n  \n  \n- (이메일 해더로부터) 이메일 라우팅(routing) 정보에 기초한 정교한\n특징을 개발.\n\n\n- 메시지 내용에 대한 정교한 특징 개발, e.g. “discount” 와\n“discounts” 를 같은 단어로 취급할 것인가? “deal” 과 “Dealer”는\n어떻게 ? 구두점(punctuation)에 대한 특징은?\n\n\n- 의도적 오타 감지를 위한 정교한 특징을 개발 (e.g. m0rtgage, med1cine, w4tches.)\n\n<hr>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 오류분석\n\n**추천 접근법**\n- 당신이 빨리 구현할 수 있는 간단한 알고리즘을 갖고 시작하시오. 그것을 구현하고, 상호-검증 자료에 대하여 시험하시오.\n\n\n- 더 많은 자료 또는 더 많은 특징 등이 도움이 될 지를 알 수 있도록 학습커브를 그려보시오.\n\n\n- 오류분석(Error analysis): 당신의 알고리즘이 오류를 생성한(상호검증자료에서의) 예들을 수동으로 검토한다. 오류가 생성되는 어떤 유형의 예에서 어떤 체계적인 경향을 발견할 수 있는 지를 본다. \n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "\n**오류분석(Error Analysis)**\n\n$m_{CV} = 500$ 교차 검증(cross validation) 세트의 예에서, \n\n알고리즘이 100 개의 이메일을 오분류하였다.\n\n수동으로 100 오류를 검토하고, 다음과 같이 분류한다:\n(i) 어떤 유형의 이메일 인가?\n(ii) 당신은 어떤 단서(특징)가 분류기가 그들을 정확히 분류하는데 도움이 된다고 생각하는가?\n\n- Pharma: 12\n- Replica/fake: 4\n- Steal passwords: 53\n- Other: 31\n\n\nIn Steal passwords (53)\n- 의도적 철자 오기: 5\n(m0rgage, med1cine, etc.)\n- 흔치 않은 이메일 라우팅(routing): 16\n- 흔치 않은 (spamming) 구두점: 32\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**수치평가(numerical evaluation)의 중요성**\n\n- discount/discounts/discounted/discounting 들을 같은 단어로 취급해야 하는가?\n\n\n- “stemming” software (E.g. “Porter stemmer”)를 사용할 수 있다.\n    universe/university.\n\n\n- 오류 분석이 이들이 성능을 개선할 수 있다고 결정하는데 도움이 되지 않을 것이다. 유일한 해결법은 시도해보고 작동되는지 보는 것이다.\n\n\n- 알고리즘의 stemming 사용과 무사용의 성능에 대한 수치검증 (e.g., cross validation error) 이 필요한다.\n\n\nWithout stemming: 5% 오차\n\nWith stemming: 3% 오차\n\nDistinguish upper vs. lower case (Mom/mom): 3.2% 오차"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 편향된(skewed) 클래스에 대한 오류 행렬\n\n**Cancer classification example**\n\n로지스틱 회귀모델 $h_\\theta(x)$ 을 훈련시켜서 ($y=1$ if cancer, $y=0$ otherwise)\n시험 자료에 대하여 1% 오류(99% 정확한 진단)를 얻었다고 하자.\n\n\n그리고, 단지 환자의 0.50% 만 암을 갖고 있다고 하면 ...\n\n다음과 같이 모든 환자가 암이 없다고 판정하는 단순한 알고리즘으로도, 0.5% 의 오류를 갖게 된다.\n\n<pre>\nfunction y = predictCancer(x)\ny = 0; %ignore x!\nreturn\n</pre>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**정확도(Precision)/재현율(Recall)**\n\n\n우리가 감지하기를 원하는 흔치 않은 클래스가 존재 하면 $y=1$ 이라 하자. \n\n\n<br>\n\n  | 1 | 0\n--|---|---\n1 | True positive | False positive\n0 | False negative | True negative\n\n\n<br>\n\n**정확도(Precision)**\n(우리가 $y=1$ 이라고 예측한 모든 환자들 중에서, 어느 비율이 실제로 암을 갖고 있는가?)\n\n$$ {\\text{True positives} \\over \\text{# of predicted positives} } = {\\text{True positives} \\over \\text{ True positive + False positive} } $$\n\n**재현율(Recall)**\n(실제로 암을 갖고 있는 모든 환자들 중에서, 어느 비율로 암을 갖고 있다고 정확히 감지했는가?)\n\n$$ {\\text{True positives} \\over \\text{# of actual positives} } = {\\text{True positives} \\over \\text{ True positive + False negative} } $$"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 정확도와 재현율 간의 상충관계(Trading off) \n\n**정확도와 재현율 상충관계**\n\n로지스틱 회귀: $ 0 \\le h_\\theta (x) \\le 1$\n\n<img src=\"./images/recall_axis.png\" width=\"200\" align=\"right\">\n\n 1 로 예측, 만약 $h_\\theta (x)  \\ge 0.5 $ \n \n0 로 예측, 만약 $h_\\theta (x)  \\lt 0.5 $ \n\n\n우리가 매우 확신할 경우에만 (cancer)\n라고 예측하기를 원한다면. $\\Rightarrow$ 높은 정확도(Higher precision), 낮은 재현율(lower recall)\n\n\n\n우리가 암의 경우를 놓치기를 피하고 싶다면\n(avoid false negatives). $\\Rightarrow$ 높은 재현율(Higher recall), 낮은 정확도(lower precision).\n\n\nMore generally: Predict 1 if $h_\\theta(x) \\ge $ threshold.\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### $F_1$ Score (F score)\n\nprecision/recall 값을 어떻게 비교하는가?\n\n|       | Precision(P)   | Recall(R) \n|-------|----------------|-----------\n| Algorithm 1 | 0.5 | 0.4\n| Algorithm 2 | 0.7 | 0.1\n| Algorithm 3 | 0.02 | 1.0\n\n\nAverage : $ { P + R  \\over 2 }$\n\n\n$F_1 $ Score: $ 2 { P R \\over P + R } $\n\n* $P = 0 \\text{ or } R = 0 \\quad \\Rightarrow \\quad \\text{F}_1 \\text{Score} = 0$ \n* $P = 1 \\text{ and } R = 1 \\quad \\Rightarrow \\quad \\text{F}_1 \\text{Score} = 1$ \n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Data for Machine learning\n\n#### 고정밀 학습 시스템 설계\n\n<img src=\"./images/train_size.png\" align=\"right\" width=\"300\">\n\nE.g. 헷갈리는 단어들을 분류하기.\n\n{to, two, too}, {then, than}\n\nFor breakfast I ate _ _ _ _ eggs.\n\nAlgorithms\n- Perceptron (Logistic regression)\n- Winnow\n- Memory-based\n- Naïve Bayes\n\n[Banko and Brill, 2001]\n\n\n“이기는 자는 최고의 알고리즘을 가진자가 아닌, 데이타를 가장 많이 가진 자다.\" \n\n\"It’s not who has the best algorithm that wins.\nIt’s who has the most data.”\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### 큰 자료 근거\n특징 $x \\in \\mathscr{R}^{n+1}$ 이 $y$ 를 정확히 예측할 수 있을 만큼 충분한\n정보를 가진다고 가정합니다.\n\n예 : For breakfast I ate _ _ _ _ eggs.\n\n\n반대 예: 다른 특징 없이, 오직 크기 ($\\text{feet}^2$) 만으로 주택가격 예측하기.\n\n\n<br>\n유용한 시험 : 주어진 입력 $x$에 대하여, 사람인 전문가는 확신을 갖고 $y$를 예측할 수 있는가? \n\n<br>\n- 많은 매개 변수를 사용한 학습 알고리즘을 사용합니다.(예: 많은 특징을 가진 로지스틱 회귀/선형 회귀; 은닉층 노드가 많은 신경망)\n$\\Rightarrow$ low bias algorithms.\n\n$\\Rightarrow  \\quad J_{train}(\\theta) $ 가 작아집니다.\n\n\n- 매우 큰 훈련 자료를 사용 (과적합되지 않도록)\n$\\Rightarrow$ low variance algorithms.\n\n$\\Rightarrow  \\quad J_{train}(\\theta) \\approx J_{test}(\\theta)$ \n\n$\\Rightarrow  \\quad J_{test}(\\theta) $ 가 작아집니다.\n\n\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}