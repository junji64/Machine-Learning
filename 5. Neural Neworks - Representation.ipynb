{
  "cells": [
    {
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "cell_type": "markdown",
      "source": "# 신경망(Neural Networks) : Representation\n\n## Non-linear hypotheses"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Non-linear Classification \n선형회귀와 로지스틱 회귀 외에, **왜 또 다른 방법이 필요**한가?\n\n  .  |  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  .  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  | \n--|--|\n<img src=\"./images/nonlinear_data_2.png\" width=\"250\"> | 로지스틱 회귀의 경우 <br> <br> $g(\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 +\\theta_3 x_1 x_2 + \\theta_4 x_1^2 x_2 + \\theta_5 x_1^3 x_2 + \\theta_6 x_1 x_2^2 + \\cdots )$ |\n\n$x_1 =$ 크기 <br>\n$x_2 =$ # 침실 <br>\n$x_3 =$ # 층 <br>\n$x_4 =$ age <br>\n$\\cdots$ <br>\n$x_{100} =$\n\n==> 특징의 개수가 많아질 때, 고차 다항식 방법(High order polynomial)은 너무 많은 매개변수를 필요로 함 "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### What is This?\n\n<img src=\"./images/car-what.png\">"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### 컴퓨터 비젼 : 자동차 감지\n\n<img src=\"./images/cars.png\">\n<hr>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<img src=\"./images/car-detect.png\" width=\"450\" align=\"left\">"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<img src=\"./images/car-detect_2.png\"  width=\"450\" align=\"left\">\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<img src=\"./images/car-recognition-3.PNG\"  width=\"550\">\n<br>\n<br>\n**따라서, 인식에 사용되는 특징들의 수가 크고, 결정 경계가 비선형이 되어야 하면, 고차항 다항식을 사용한 로지스틱 회귀 보다는 다른 방법(e.g. 인공신경망방법)이 바람직하다.**"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## Neurons and the brain\n\n#### Neural Networks\n\n* 기원 (1950년대 부터) : 뇌를 모방하려고 하는 알고리즘.\n* 80 년대와 90 년대 초에 매우 널리 사용되었습니다. \n* 90년대 후반에 인기가 떨어졌습니다.\n* 최근 2010년 이후 부활 : 딥러닝 알고리즘의 개발, GPU 활용한 빠른 계산 가능, 및 충분한 훈련자료의 확보가 가능해지면서, 많은 응용 분야에서 최첨단 기술로 활용 중.\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### \"한가지 학습 알고리즘\" 가설\n청각 피질(auditory cortex)이 시각을 학습합니다.\n<img src=\"./images/auditory_cortex.png\" width=\"400\">\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### \"한가지 학습 알고리즘\" 가설\n\n체성감각 피질(somatosensory cortex)이 시각을 학습합니다.\n<img src=\"./images/somatosensory_cortex.png\" width=\"400\">\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "\n#### Sensor representations in the brain\n<img src=\"./images/sensor_in_the_brain.png\">\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 모델 표현 I\n\n#### 뇌속의 신경세포\n\n<img src=\"./images/neuron_cell.png\" width=\"350\">"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<img src=\"./images/neuron_cells.png\" width=\"300\">"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### 신경세포 모델 : 논리 유닛 (Logistic unit)\n\n<img src=\"./images/nn_one.png\" width=\"200\">\n\n$ x = \\begin{bmatrix}\nx_0 \\\\\nx_1 \\\\\nx_2 \\\\\nx_3\n\\end{bmatrix}\n$\n$ \\quad  \\theta = \\begin{bmatrix}\n\\theta_0 \\\\\n\\theta_1 \\\\\n\\theta_2 \\\\\n\\theta_3\n\\end{bmatrix}\n\\quad \\quad $\nSigmoid (logistic) 활성함수\n\n<br>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Neural Network**\n\n\n<img src=\"./images/nn_two.png\" width=\"400\">\n\n<br>\n\n<br>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**neural network**\n\n<img src=\"./images/nn_two.png\" width=\"200\" align=\"left\">\n\n<br>\n<br>\n$\\quad a_i^{(j)} = $ j-층의 i-유닛의 \"활성\"\n\n$\\quad \\Theta^{(j)} =$ j-층에서 j+1층으로의 함수 매핑을 제어하는 가중치 행렬\n\n<br>\n\n<br>\n\n$$ a_1^{(2)} = g( \\Theta_{10}^{(1)}x_0 + \\Theta_{11}^{(1)}x_1 + \\Theta_{12}^{(1)}x_2 + \\Theta_{13}^{(1)}x_3 )$$\n$$ a_2^{(2)} = g( \\Theta_{20}^{(1)}x_0 + \\Theta_{21}^{(1)}x_1 + \\Theta_{22}^{(1)}x_2 + \\Theta_{23}^{(1)}x_3 )$$\n$$ a_3^{(2)} = g( \\Theta_{30}^{(1)}x_0 + \\Theta_{31}^{(1)}x_1 + \\Theta_{32}^{(1)}x_2 + \\Theta_{33}^{(1)}x_3 )$$\n\n$$ h_\\Theta (x) =  a_1^{(3)} = g( \\Theta_{10}^{(2)}a_0^{(2)} + \\Theta_{11}^{(2)}a_1^{(2)} + \\Theta_{12}^{(2)}a_2^{(2)} + \\Theta_{13}^{(2)}a_3^{(2)} )$$\n\n네트워크에 $j$ 층에 $s_j$ 유닛이 그리고, $j+1$ 층에 $s_{j+1}$ 유닛이 있으면, $\\Theta^{(j)}$ 의 크기는 $s_{j+1} \\times (s_j + 1)$ 이 된다."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## 모델 표현 II\n\n#### 전방향전파 : 벡터화 구현\n<img src=\"./images/nn_two.png\" width=\"250\">\n\n$$ a_1^{(2)} = g( \\Theta_{10}^{(1)}x_0 + \\Theta_{11}^{(1)}x_1 + \\Theta_{12}^{(1)}x_2 + \\Theta_{13}^{(1)}x_3 )$$\n$$ a_2^{(2)} = g( \\Theta_{20}^{(1)}x_0 + \\Theta_{21}^{(1)}x_1 + \\Theta_{22}^{(1)}x_2 + \\Theta_{23}^{(1)}x_3 )$$\n$$ a_3^{(2)} = g( \\Theta_{30}^{(1)}x_0 + \\Theta_{31}^{(1)}x_1 + \\Theta_{32}^{(1)}x_2 + \\Theta_{33}^{(1)}x_3 )$$\n\n$$ h_\\Theta (x) =  a_1^{(3)} = g( \\Theta_{10}^{(2)}a_0^{(2)} + \\Theta_{11}^{(2)}a_1^{(2)} + \\Theta_{12}^{(2)}a_2^{(2)} + \\Theta_{13}^{(2)}a_3^{(2)} )$$\n\n$ x = \\begin{bmatrix}\nx_0 \\\\\nx_1 \\\\\nx_2 \\\\\nx_3\n\\end{bmatrix}\n$\n$ \\quad z^{(2)} = \\begin{bmatrix}\nz_1^{(2)} \\\\\nz_2^{(2)} \\\\\nz_3^{(2)} \\\\\n\\end{bmatrix}\n\\quad $\n\nAdd $x_0 = 1$\n\n$z^{(2)} = \\Theta^{(1)}x = \\Theta^{(1)}a^{(1)}$ <br>\n$a^{(2)} = g(z^{(2)})$ <br>\n\nAdd $a_0^{(2)} = 1.$\n\n$z^{(3)} = \\Theta^{(2)}a^{(2)}$<br>\n$h_\\theta(x) = a^{(3)} = g(z^{(3)})$"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### 자신의 특징을 학습하는 신경망\n\n<img src=\"./images/nn_two.png\" width=\"350\">\n\n<br>\n$$ h_\\Theta (x) =  g( \\Theta_{10}^{(2)}a_0^{(2)} + \\Theta_{11}^{(2)}a_1^{(2)} + \\Theta_{12}^{(2)}a_2^{(2)} + \\Theta_{13}^{(2)}a_3^{(2)} )$$\n<br>\n$$x_1, x_2, x_3 \\quad \\rightarrow \\quad a_1^{(2)},a_2^{(2)},a_3^{(2)}$$\n<br>\n\n<br>\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Other network architectures**\n\n<img src=\"./images/nn_three.png\" width=\"450\">\n\n<br>\n\n<br>\n\n<br>\n\n<br>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Examples and intituitions I\n\n#### 비선형 분류 예 : XOR, XNOR\n\n$x_1, x_2$는 이진수(binary) (0 or 1)\n\n<img src=\"./images/xor_0.png\" width=\"200\" align=\"left\">\n<img src=\"./images/xor.png\" width=\"200\">\n\n$ y = x_1 \\text{ XOR } x_2 $\n \n$ y = x_1 \\text{ XNOR } x_2 = \\text{NOT } (x_1 \\text{ XOR } x_2)$\n\n<br>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Simple example: AND\n\n$x_1, x_2 \\in \\{0, 1\\}$\n\n$y = x_1 \\text{ AND } x_2 $\n\nlet $ w_0 = -30, w_1=20, w_2=20$\n\n<img src=\"./images/NN_and.png\" width=\"250\" align=\"left\">\n\n>\n\n| $x_1$ | $x_2$ | $h_\\theta(x)$\n|-------|-------|--------------\n|  0    |   0   | $g(-30) \\approx 0$\n|  0    |   1   |$g(-10) \\approx 0$\n|  1    |   0   |$g(-10) \\approx 0$\n|  1    |   1   |$g(10) \\approx 1$\n\n$ h_\\Theta (x) =  g( -30 +20 x_1 + 20 x_2 )$\n<br>\n\n<br>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "\n#### Simple example: OR\n\n$x_1, x_2 \\in \\{0, 1\\}$\n\n$y = x_1 \\text{ OR } x_2$\n\nlet $ w_0 = -10, w_1=20, w_2=20$\n\n<img src=\"./images/NN_and.png\" width=\"250\" align=\"left\">\n\n>\n\n| $x_1$ | $x_2$ | $h_\\theta(x)$\n|-------|-------|--------------\n|  0    |   0   | $g(-10) \\approx 0$\n|  0    |   1   |$g(10) \\approx 1$\n|  1    |   0   |\n|  1    |   1   |\n\n$ h_\\Theta (x) =  g( -10 +20 x_1 + 20 x_2 )$\n<br>\n\n<br>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Simple example: NOT\n\n$x_1 \\in \\{0, 1\\}$\n\n$y = \\text{ NOT } x_1$\n\nlet $ w_0 =10, w_1=-20 \\quad \\quad \\rightarrow \\quad  \\quad  h_\\Theta (x) =  g(10 - 20 x_1 )$\n\n<img src=\"./images/NN_not.png\" width=\"250\" align=\"left\">\n\n>\n\n| $x_1$ |  $h_\\theta(x)$\n|-------|--------------\n|  0    |  $g(10) \\approx 1$\n|  1    |  $g(-10) \\approx 0$\n\n\n\n#### Simple example: \n$ y = (\\text{NOT} x_1) \\text{ AND } (\\text{NOT} x_2) $\n\nlet $ w_0 =10, w_1=-20, w_2=-20$\n\n<img src=\"./images/NN_and.png\" width=\"200\" align=\"left\"> \n\n| $x_1$ | $x_2$ | $h_\\theta(x)$\n|-------|-------|--------------\n|  0    |   0   | $g(10) \\approx 1$\n|  0    |   1   |$g(-10) \\approx 0$\n|  1    |   0   |$g(-10) \\approx 0$\n|  1    |   1   |$g(-30) \\approx 0$"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Putting Together: $x_1$ XNOR $x_2$\n\n\n$y = x_1$ XNOR $x_2$\n\n.. | .. | .. |\n---|---|---|\n<img src=\"./images/NN_and.png\" width=\"200\" align=\"left\"> | <img src=\"./images/NN_and.png\" width=\"200\" align=\"left\"> | <img src=\"./images/NN_and.png\" width=\"200\" align=\"left\"> | \n$x_1$ AND $x_2  $ | (NOT $x_1$) AND (NOT $x_2$) | $x_1$ OR $ $x_2$ |\n\n<br> \n<img src=\"./images/XNOR.PNG\" width=\"270\" align=\"left\"> \n\n|  $x_1$ |  $x_2$ |  $a_1^{(2)}$  |  $a_2^{(2)}$  | $h_\\theta(x)$\n|--------|--------|---------------|---------------|---------------\n|  0    |   0   |             |             | $g(10) \\approx 1$\n|  0    |   1   |             |             | $g(-10) \\approx 0$\n|  1    |   0   |             |             | $g(-10) \\approx 0$\n|  1    |   1   |             |             | $g(10) \\approx 1$\n\n<br>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Handwritten Digit Recognition (Demonstration)\n\n<img src=\"./images/handwritten_digits.png\" width=\"500\" >\n[link_to_video](https://youtu.be/yxuRnBEczUU)"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "from IPython.display import IFrame\n\n# Youtube\nIFrame('https://youtu.be/yxuRnBEczUU', width=560, height=315)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 다중 클래스 분류(Multi-class classification)\n\n#### Multiple output units : One-vs-all\n\n<img src=\"./images/multiple_out_NN.png\" width=\"550\">\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "#### Multiple output units : One-vs-all\n<br>\n\n<img src=\"./images/multiclass.PNG\" width=\"550\" align=\"left\">\n\n<br>\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
