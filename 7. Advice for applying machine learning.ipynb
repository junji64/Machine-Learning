{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝 적용을 위한 조언\n",
    "\n",
    "## 다음에 무엇을 할 지 결정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 학습 알고리즘 디버깅:\n",
    "\n",
    "당신이 집 가격을 예측하기 위해서 정규화된 선형회귀를 구현했다고 가정해보자.\n",
    "\n",
    "\n",
    "$$J(\\theta) =  { 1 \\over 2m} \\left[ \\sum_{i=1}^m (h_\\theta(x^{(i)})- y^{(i)})^2 +   \\lambda \\sum_{j=1}^n \\theta_j^2 \\right]$$\n",
    "\n",
    "\n",
    "그러나, 당신의 가설을 새로운 집들 자료에 시험했을 때, 그 추측에서 받아드릴 수\n",
    "없을 정도로 큰 오차를 만드는 것을 발견했다. 당신은 다음에 무엇을 시도해야\n",
    "하는가?\n",
    "\n",
    "* 더 많은 훈련자료를 얻는다. \n",
    "\n",
    "* 더 적은 특징집합으로 시도해본다.\n",
    "\n",
    "* 추가적인 특징들로 시도해본다.\n",
    "\n",
    "* 특징의 고차원 항들을 추가해 본다. $(x_1^2, x_2^2, x_1x_2, etc.)$\n",
    "\n",
    "* $\\lambda$ 를 감소시켜본다.\n",
    "\n",
    "* $\\lambda$ 를 증가시켜본다.\n",
    "\n",
    "$\\Rightarrow $ 어떤 시도는 오랜 시간이 필요하기도 하고,  어떨 때는 나아지고, 어떨 때는 그렇지 못함 $\\therefore$ 무작위적 선택은 옳지 않음 !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기계 학습 진단:\n",
    "\n",
    "**진단** : 학습알고리즘에서 무엇이 작동하고 / 작동하지 않는 지에 대한 통찰을 얻기 위해서 당신이 실행할 수 있는 시험\n",
    "그리고 그 성능을 어떻게 최대로 개선할 수 있는 지에 대한 안내 얻기 위해서 당신이 실행할 수 있는 시험. \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "진단은 구현에 시간이 많이 걸릴 수는 있으나, 실행하는 것이 당신의 시간을 가장 잘 사용하는 것일 수 있다.\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 가설(hypothesis) 평가하기\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/reg-graph.PNG\" width=\"200\" align=\"left\" >\n",
    "\n",
    "$\\quad \\begin{align}\n",
    "\\quad x_1 = & \\text{ size of house }\\\\\n",
    "\\quad x_2 = & \\text{ no. of bedrooms } \\\\\n",
    "\\quad x_3 = & \\text{ no. of floors } \\\\\n",
    "\\quad x_4 = & \\text{ age of house } \\\\\n",
    "\\quad x_5 = & \\text{ average income in neighborhood }\\\\\n",
    "\\quad x_6 = & \\text{ kitchen size } \\\\\n",
    "\\quad \\vdots & \\vdots \\\\\n",
    "\\quad \\quad  x_{100} = & \\\\\n",
    "\\quad \\end{align}$ \n",
    "\n",
    "\n",
    "$ h_\\theta(x) = \\theta_0 + \\theta_1 x +\\theta_2 x^2 +\\theta_3 x^3 +\\theta_4 x^4 $\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "훈련자료 집합에 없는 새로운 자료에 일반화하는데 실패할 경우, 많은 특징을 사용하는 가설의 경우에는 실패 원인을 그래프로 확인하는데는 한계가 있음.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating your hypothesis\n",
    "\n",
    "Dataset: 훈련자료(70%)와 시험자료(30%) 두 부분으로 나눔 (무작위적으로)\n",
    "\n",
    "| Size | Price |      \n",
    "|------|-------|------- \n",
    "| 2104 | 400   |  $(x^{(1)}, y^{(1)})$\n",
    "|1600 | 330  |  $(x^{(2)}, y^{(2)})$\n",
    "| 2400 | 369 | $\\vdots$\n",
    "|1416 | 232| $\\vdots$\n",
    "| 3000 | 540| $\\vdots$\n",
    "| 1985 | 300| $(x^{(m)}, y^{(m)})$\n",
    "|1534 | 315  |   $(x_{test}^{(1)}, y_{test}^{(1)})$\n",
    "| 1427 | 199  | $(x_{test}^{(2)}, y_{test}^{(2)})$\n",
    "| 1380 | 212   |  $\\vdots$\n",
    "| 1494 | 243  |  $(x_{test}^{(m_{test})}, y_{test}^{(m_{test})})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 선형회귀에 대한 훈련/시험과정\n",
    "\n",
    "- 훈련자료(training set)로부터 파라메타 $\\theta$를 학습 (훈련 오차 $J(\\theta)$ 를 최소화함으로 )\n",
    "\n",
    "$$ \\min_\\theta J(\\theta) $$\n",
    "\n",
    "- 시험집합(test set) 오차를 계산 :\n",
    "\n",
    "$$ J_{test}(\\theta) = { 1 \\over 2 m_{test} } \\sum_{i=1}^{m_{test}}  (h_\\theta(x_{test}^{(i)}) - y_{test}^{(i)}  )^2 $$\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 로지스틱회귀에 대한 훈련/시험 과정\n",
    "\n",
    "* 훈련자료로부터 파라메타 를 학습\n",
    "\n",
    "* 시험집합(test set) 오차를 계산 :\n",
    "\n",
    "$$ J_{test}(\\theta) = {1 \\over m_{test}}  \\sum_{i=1}^{m_{test}}  y_{test}^{(i)} \\log (h_\\theta(x_{test}^{(i)})) + (1 -y_{test}^{(i)}) \\log (1-h_\\theta(x_{test}^{(i)}))$$\n",
    "\n",
    "\n",
    "* (or) 오분류 오차 (0/1 misclassification error):\n",
    "\n",
    "$$ err(h_\\theta(x), y) =\n",
    "  \\begin{cases}\n",
    "    1  & \\quad \\text{if } h_\\theta(x) \\ge 0.5, y=0 \\text{ or if }  h_\\theta(x) < 0.5, y=1\\\\\n",
    "    0  & \\quad \\text{otherwise }\n",
    "  \\end{cases}$$\n",
    "  \n",
    "  $$ Error_{test} = { 1 \\over m_{test} } \\sum_{i=1}^{m_{test}} err(h_\\theta(x_{test}^{(i)}), y_{test}^{(i)}) $$\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 선택과 훈련/검증/시험 집합들\n",
    "\n",
    "**모델 선택** : 다항식의 차수 $d$, 정규화 상수 $\\lambda$ 를 어떻게 선택해야 하는가?\n",
    "\n",
    "#### 과적합(Overfitting) 예\n",
    "\n",
    "<img src=\"./images/reg-graph.PNG\" width=\"200\" >\n",
    "\n",
    "$ h_\\theta(x) = \\theta_0 + \\theta_1 x +\\theta_2 x^2 +\\theta_3 x^3 +\\theta_4 x^4 $\n",
    "\n",
    "$\\theta_0,\\theta_1,\\cdots,\\theta_4$ 파라메타들이 어떤 자료집합(훈련자료)에 적합되면,\n",
    "그 자료에 대한 파라메타들로 추정된 값의 오차 ( $J(\\theta)$의 훈련자료 오차 ) 는 실제 일반화된 오차보다 낮을 가능성이 있다.\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 선택\n",
    "\n",
    "$d = $ \"다항식의 차수\"를 결정하기.\n",
    "\n",
    "1. $h_\\theta (x) = \\theta_0 + \\theta_1 x \\quad \\rightarrow \\quad \\theta^{(1)} \\quad \\rightarrow \\quad J_{test}(\\theta^{(1)})$ \n",
    "\n",
    "2. $h_\\theta (x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2  \\quad \\rightarrow \\quad \\theta^{(2)} \\quad \\rightarrow \\quad J_{test}(\\theta^{(2)})$ \n",
    "\n",
    "3. $h_\\theta (x) = \\theta_0 + \\theta_1 x + \\cdots + \\theta_3 x^3  \\quad \\rightarrow \\quad \\theta^{(3)} \\quad \\rightarrow \\quad J_{test}(\\theta^{(3)})$ \n",
    "\n",
    "$\\vdots$\n",
    "\n",
    "10.  $h_\\theta (x) = \\theta_0 + \\theta_1 x + \\cdots + \\theta_{10} x^{10}  \\quad \\rightarrow \\quad \\theta^{(10)} \\quad \\rightarrow \\quad J_{test}(\\theta^{(10)})$\n",
    "\n",
    "\n",
    "* 만약 $J_{test}(\\theta^{(1)}) \\sim J_{test}(\\theta^{(10)})$ 로부터 가장 작은 비용을 주는 $ \\theta_0 + \\theta_1 x + \\cdots + \\theta_5 x^5$ 이 선택되면\n",
    "\n",
    "\n",
    "* 모델이 얼마나 잘 일반화하는가? 시험 집합에 대한 오차 $J_{test}(\\theta^{(5)})$를 살펴본다.\n",
    "\n",
    "\n",
    "* 문제: $J_{test}(\\theta^{(5)})$ 는 일반화 오차의 낙관적 추정일 가능성이 있다. 즉, 우리의 추가 파라메타 ($d =$ degree of polynomial) 가 시험자료에 적합시킨 것이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가설 평가(Evaluating your hypothesis)\n",
    "\n",
    "Dataset: 훈련/검증/시험 세 부분으로 나눔. \n",
    "\n",
    "| Size | Price | \n",
    "|------|-------|------- \n",
    "| 2104 | 400   |  $(x^{(1)}, y^{(1)})$\n",
    "|1600 | 330  |  $(x^{(2)}, y^{(2)})$\n",
    "| 2400 | 369 | $\\vdots$\n",
    "|1416 | 232| $(x^{(m)}, y^{(m)})$\n",
    "| 3000 | 540| $(x_{CV}^{(1)}, y_{CV}^{(1)})$\n",
    "| 1985 | 300| $\\vdots$\n",
    "|1534 | 315  |   $(x_{CV}^{(m_{CV})}, y_{CV}^{(m_{CV})})$\n",
    "| 1427 | 199  | $(x_{test}^{(1)}, y_{test}^{(1)})$\n",
    "| 1380 | 212   |  $\\vdots$\n",
    "| 1494 | 243  |  $(x_{test}^{(m_{test})}, y_{test}^{(m_{test})})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련/검증/테스트 오차\n",
    "\n",
    "** 훈련(Training) error:**\n",
    "$$J_{train}(\\theta) =  { 1 \\over 2m} \\sum_{i=1}^m (h_\\theta(x^{(i)})- y^{(i)})^2 $$\n",
    "\n",
    "** 교차검증(Cross Validation) error:**\n",
    "$$J_{CV}(\\theta) =  { 1 \\over 2m_{CV}} \\sum_{i=1}^{m_{CV}} (h_\\theta(x_{CV}^{(i)})- y_{CV}^{(i)})^2 $$\n",
    "\n",
    "** 시험(Test) error:**\n",
    "$$J_{test}(\\theta) =  { 1 \\over 2m_{test}} \\sum_{i=1}^{m_{test}} (h_\\theta(x_{test}^{(i)})- y_{test}^{(i)})^2 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 모델 선택\n",
    "\n",
    "1. $h_\\theta (x) = \\theta_0 + \\theta_1 x  \\quad \\rightarrow \\quad \\theta^{(1)} \\quad \\rightarrow \\quad J_{CV}(\\theta^{(1)})$ \n",
    "\n",
    "2. $h_\\theta (x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 \\quad \\rightarrow \\quad \\theta^{(2)} \\quad \\rightarrow \\quad J_{CV}(\\theta^{(2)})$ \n",
    "\n",
    "3. $h_\\theta (x) = \\theta_0 + \\theta_1 x + \\cdots + \\theta_3 x^3 \\quad \\rightarrow \\quad \\theta^{(3)} \\quad \\rightarrow \\quad J_{CV}(\\theta^{(3)})$ \n",
    "\n",
    "$\\vdots$\n",
    "\n",
    "10.  $h_\\theta (x) = \\theta_0 + \\theta_1 x + \\cdots + \\theta_{10} x^{10} \\quad \\rightarrow \\quad \\theta^{(10)} \\quad \\rightarrow \\quad J_{CV}(\\theta^{(10)})$ \n",
    "\n",
    "\n",
    "* 만약 $J_{CV}(\\theta^{(1)}) \\sim J_{CV}(\\theta^{(10)})$ 로부터 가장 작은 비용을 주는  $ \\theta_0 + \\theta_1 x + \\cdots + \\theta_4 x^4$ 이 선택되면\n",
    "\n",
    "\n",
    "* 시험 집합에 대한 오차$J_{test}(\\theta^{(4)})$로 일반화 오차를 평가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 바이어스 vs. 분산 진단하기\n",
    "\n",
    "대부분의 머신러닝 알고리즘이 처음에 제대로 동작하지 않으면 사용된 가설이 높은 바이어스(bias) 문제거나 높은 분산(variance)의 문제인 경우이다. \n",
    "\n",
    "#### 바이어스/분산\n",
    "\n",
    "| underfit, High bias | Just Right  |Overfit, Hight variance |\n",
    "|---------|--------|--------|\n",
    "|<img src=\"./images/reg-graph.PNG\" width=\"180\"> |<img src=\"./images/reg-graph.PNG\" width=\"180\"> | <img src=\"./images/reg-graph.PNG\" width=\"180\">|\n",
    "|$\\theta_0 + \\theta_1 x$ | $\\theta_0 + \\theta_1 x +\\theta_2 x^2$ | $\\theta_0 + \\theta_1 x +\\theta_2 x^2 +\\theta_3 x^3 +\\theta_4 x^4$ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 바이어스/분산\n",
    "\n",
    "Training error : $J_{train}(\\theta) =  { 1 \\over 2m} \\sum_{i=1}^m (h_\\theta(x^{(i)})- y^{(i)})^2 $\n",
    "\n",
    "Cross validation error : $J_{CV}(\\theta) =  { 1 \\over 2m_{CV}} \\sum_{i=1}^{m_{CV}} (h_\\theta(x_{CV}^{(i)})- y_{CV}^{(i)})^2 $\n",
    "\n",
    "| underfit, High bias | Just Right  |Overfit, Hight variance |\n",
    "|---------|--------|--------|\n",
    "|<img src=\"./images/reg-graph.PNG\" width=\"100\"> |<img src=\"./images/axis.PNG\" width=\"300\"  >| <img src=\"./images/reg-graph.PNG\" width=\"100\">|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 바이어스 vs. 분산 진단\n",
    "\n",
    "학습 알고리즘이 기대했던 것보다 성능이 떨어진다고 가정하십시오. ($J_{CV}(\\theta)$ 또는 $J_{test}(\\theta)$가 높음) 바이어스 문제입니까 아니면 분산 문제입니까?\n",
    "\n",
    "<img src=\"./images/bias_variance.png\" WIDTH=\"300\" ALIGN=\"left\"> \n",
    "Bias(underfit): \n",
    "\n",
    "$$ J_{train}(\\theta) \\text { will be high }$$\n",
    "\n",
    "$$ J_{CV} (\\theta) \\approx J_{train}(\\theta) $$\n",
    "\n",
    "Variance (overfit):\n",
    "\n",
    "$$ J_{train}(\\theta) \\text{ will be low }$$\n",
    "\n",
    "$$ J_{CV} (\\theta) >> J_{train}(\\theta) $$\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정규화와 바이어스/분산\n",
    "\n",
    "#### 정규화 선형회귀\n",
    "\n",
    "Model : \n",
    "\n",
    "$$ h_\\theta (x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3 + \\theta_4 x^4 $$\n",
    "\n",
    "$$J(\\theta) =  { 1 \\over 2m} \\left[ \\sum_{i=1}^m (h_\\theta(x^{(i)})- y^{(i)})^2 +   \\lambda \\sum_{j=1}^n \\theta_j^2 \\right]$$\n",
    "\n",
    "| underfit, High bias | Just Right  |Overfit, Hight variance |\n",
    "|---------|--------|--------|\n",
    "|<img src=\"./images/reg-graph.PNG\" width=\"180\"> |<img src=\"./images/reg-graph.PNG\" width=\"180\"> | <img src=\"./images/reg-graph.PNG\" width=\"180\">|\n",
    "| Large $\\lambda \\approx 10000$ |  Intermediate $\\lambda$  |  Small $\\lambda \\approx 0$  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정규화 매개변수 $\\lambda$ 선택하기\n",
    "\n",
    "$$ h_\\theta (x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3 + \\theta_4 x^4 $$\n",
    "\n",
    "$$J(\\theta) =  { 1 \\over 2m} \\left[ \\sum_{i=1}^m (h_\\theta(x^{(i)})- y^{(i)})^2 +   \\lambda \\sum_{j=1}^n \\theta_j^2 \\right]$$\n",
    "\n",
    "\n",
    "\n",
    "$$J_{train}(\\theta) =  { 1 \\over 2m} \\sum_{i=1}^m (h_\\theta(x^{(i)})- y^{(i)})^2 $$\n",
    "\n",
    "$$J_{CV}(\\theta) =  { 1 \\over 2m_{CV}} \\sum_{i=1}^{m_{CV}} (h_\\theta(x_{CV}^{(i)})- y_{CV}^{(i)})^2 $$\n",
    "\n",
    "$$J_{test}(\\theta) =  { 1 \\over 2m_{test}} \\sum_{i=1}^{m_{test}} (h_\\theta(x_{test}^{(i)})- y_{test}^{(i)})^2 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**정규화 파라메타 $\\lambda$ 선택**\n",
    "\n",
    "Model : \n",
    "\n",
    "$$ h_\\theta (x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3 + \\theta_4 x^4$$\n",
    "\n",
    "$$J(\\theta) = {1 \\over 2m} \\left[ \\sum_{i=1}^m(h_\\theta(x^{(i)})- y^{(i)})^2 + \\lambda \\sum_{j=1}^n \\theta_j^2 \\right] $$\n",
    "\n",
    "1. $ \\lambda =   0 \\quad \\quad \\rightarrow \\quad \\min_\\theta J(\\theta) \\quad \\rightarrow \\quad \\theta^{(1)} \\quad \\rightarrow \\quad J_{CV}(\\theta^{(1)})$\n",
    "2. $  \\lambda =   0.01 \\quad \\rightarrow \\quad \\min_\\theta J(\\theta) \\quad \\rightarrow \\quad \\theta^{(2)} \\quad \\rightarrow \\quad J_{CV}(\\theta^{(2)})$ \n",
    "3. $   \\lambda =   0.02 \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\rightarrow \\quad \\theta^{(3)} \\quad \\rightarrow \\quad J_{CV}(\\theta^{(3)})$ \n",
    "4. $  \\lambda =   0.04 \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\rightarrow \\quad \\theta^{(4)} \\quad \\rightarrow \\quad J_{CV}(\\theta^{(4)})$ \n",
    "5. $   \\lambda =   0.08 \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\rightarrow \\quad \\theta^{(5)} \\quad \\rightarrow \\quad J_{CV}(\\theta^{(4)})$ \n",
    "$ \\vdots &  $ \n",
    "12. $   \\lambda =   10 \\quad \\quad \\quad \\quad \\quad \\quad \\quad  \\rightarrow \\quad \\theta^{(10)} \\quad \\rightarrow \\quad J_{CV}(\\theta^{(10)})$ \n",
    "\n",
    "\n",
    "(만약) $\\theta^{(5)}$를 선택하면, 시험오차는 $J_{test}(\\theta^{(5)})$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 정규화 매개변수 $\\lambda$ 의 함수로서 바이어스/분산\n",
    "\n",
    "\n",
    "<img src=\"./images/axis.PNG\" width=\"300\"  align=\"right\">\n",
    "\n",
    "<br>\n",
    "$$J(\\theta) =  { 1 \\over 2m} \\left[ \\sum_{i=1}^m (h_\\theta(x^{(i)})- y^{(i)})^2 +   \\lambda \\sum_{j=1}^n \\theta_j^2 \\right]$$\n",
    "\n",
    "\n",
    "$$J_{train}(\\theta) =  { 1 \\over 2m} \\sum_{i=1}^m (h_\\theta(x^{(i)})- y^{(i)})^2 $$\n",
    "\n",
    "$$J_{CV}(\\theta) =  { 1 \\over 2m_{CV}} \\sum_{i=1}^{m_{CV}} (h_\\theta(x_{CV}^{(i)})- y_{CV}^{(i)})^2 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습곡선(Learning Curve)\n",
    "\n",
    "훈련자료 수의 변화에 따른 훈련(train)오차와 상호검증(CV)오차를 표시한 그래프\n",
    "\n",
    "$$ h_\\theta (x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 $$\n",
    "\n",
    "<img src=\"./images/six_graph_1.PNG\" width=\"350\" align=\"right\"  >\n",
    "\n",
    "$$J_{train}(\\theta) =  { 1 \\over 2m} \\sum_{i=1}^m (h_\\theta(x^{(i)})- y^{(i)})^2 $$\n",
    "\n",
    "$$J_{CV}(\\theta) =  { 1 \\over 2m_{CV}} \\sum_{i=1}^{m_{CV}} (h_\\theta(x_{CV}^{(i)})- y_{CV}^{(i)})^2 $$\n",
    "\n",
    "\n",
    "<img src=\"./images/axis.PNG\" width=\"250\" align=\"left\" >\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**High Bias**\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<img src=\"./images/axis.PNG\" width=\"230\"  align=\"left\" > \n",
    "$$ h_\\theta (x) = \\theta_0 + \\theta_1 x  $$\n",
    "<img src=\"./images/learning_curve_1.PNG\" width=\"250\" >\n",
    "학습 알고리즘에 높은 편견이 있는 경우 더 많은 교육 데이터를 얻는 것이 그 자체로는 큰 도움이 되지 않습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**High Variance**\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/axis.PNG\" width=\"250\"  align=\"left\" > \n",
    "$$ h_\\theta (x) = \\theta_0 + \\theta_1 x + \\cdots + \\theta_{100}x^{100}$$\n",
    "<img src=\"./images/learning_curve_2.PNG\" width=\"250\"  >\n",
    "학습 알고리즘이 높은 분산의 영향을 받는 경우에는, 더 많은 학습 데이터를 얻는 것이 도움이 될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다음에 시도 할 사항 결정 (재검토)\n",
    "\n",
    "학습 알고리즘 디버깅 :\n",
    "\n",
    "주택 가격을 예측하기 위해 정규화 된 선형회귀를 구현했다고 가정 해보십시오. 그러나 새 집 집합에서 가설을 테스트하면 예측에서 허용 할 수 없을 정도로 큰 오류가 발생합니다. 다음에 무엇을 시도해야 합니까?\n",
    "\n",
    "* 더 많은 훈련 예를 얻으십시오\n",
    "* 더 작은 특징 세트 사용해보기\n",
    "* 추가 특징을 사용해보십시오\n",
    "* 다항식 특징 추가\n",
    "* $\\lambda$ 감소 시도\n",
    "* $\\lambda$ 증가 시도\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**신경망과 과적합**\n",
    "\n",
    "\"작은\" 신경망 (파라메타가 적을수록 미적합 경향이 있음)\n",
    "<img src=\"./images/small_NN.png\">\n",
    "계산상 저렴\n",
    "\n",
    "***\n",
    "\n",
    "\"큰\" 신경망 (더 많은 파라메타; 과적합하기 더 쉽습니다)\n",
    "<img src=\"./images/large_NN.png\">\n",
    "\n",
    "계산 상 더 비싸다.\n",
    "\n",
    "정규화($\\lambda$)를 사용하여 과적합을 처리하십시오.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
